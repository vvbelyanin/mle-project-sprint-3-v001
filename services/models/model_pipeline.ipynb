{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c079e746",
   "metadata": {},
   "source": [
    "#### Часть кода пайплайна для генерации модели с предыдущего проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8635bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary standard libraries\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Import third-party libraries for AWS interactions, model handling, HTTP requests, random number generation, and data manipulation\n",
    "import boto3\n",
    "import joblib\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Load environment variables from a .env file and pretty print module for more readable outputs\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "# SQLAlchemy for database interactions\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Machine learning and feature engineering libraries\n",
    "from autofeat import AutoFeatRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Import necessary components from scikit-learn for building and evaluating machine learning models\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, make_scorer, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer, PowerTransformer, PolynomialFeatures, scale\n",
    "\n",
    "# Configure pandas display options for better readability of floating point numbers\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# Set warning level for matplotlib to suppress warnings\n",
    "plt.set_loglevel('WARNING')\n",
    "\n",
    "# Define constants for database interactions and geographical calculations\n",
    "TABLE_NAME = 'clean_flats'\n",
    "MOSCOW_CENTER = (55.751610795409086, 37.61799504180682)\n",
    "\n",
    "# Set random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "random.seed(RANDOM_STATE) \n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ac0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a database engine\n",
    "def get_engine():\n",
    "    \"\"\"\n",
    "    Create and return a SQLAlchemy engine using environment variables for database connection.\n",
    "    \"\"\"\n",
    "    return create_engine(f\"postgresql://{os.getenv('DB_DESTINATION_USER')}:\"\n",
    "                         f\"{os.getenv('DB_DESTINATION_PASSWORD')}@\"\n",
    "                         f\"{os.getenv('DB_DESTINATION_HOST')}:\"\n",
    "                         f\"{os.getenv('DB_DESTINATION_PORT')}/\"\n",
    "                         f\"{os.getenv('DB_DESTINATION_NAME')}\")\n",
    "\n",
    "# Function to load a dataframe from a database table\n",
    "def load_df(table_name):\n",
    "    \"\"\"\n",
    "    Load and return a dataframe from the specified table in the database.\n",
    "    \"\"\"\n",
    "    return pd.read_sql(sql=f'SELECT * FROM {table_name}', con=get_engine())\n",
    "\n",
    "# Function to display statistics of a dataframe\n",
    "def display_statistics(data):\n",
    "    \"\"\"\n",
    "    Display various statistics for each column in the dataframe.\n",
    "    \"\"\"\n",
    "    def lo_hi_count(data, col, low=True):\n",
    "        \"\"\"\n",
    "        Calculate and return the count of outliers in a column based on the IQR method.\n",
    "        \"\"\"\n",
    "        if data[col].dtype not in [float, int, 'datetime64[ns]']:\n",
    "            return '---'\n",
    "        Q1 = np.nanquantile(data[col], 0.25)\n",
    "        Q3 = np.nanquantile(data[col], 0.75)\n",
    "        if low:\n",
    "            return data[data[col] <= (Q1 - 1.5 * (Q3 - Q1))][col].count()\n",
    "        else:\n",
    "            return data[data[col] >= (Q3 + 1.5 * (Q3 - Q1))][col].count()\n",
    "    \n",
    "    # Create and return a dataframe with statistics for each column\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            'type': [data[x].dtypes for x in data.columns],\n",
    "            'count': [data[x].count() for x in data.columns],\n",
    "            'NaNs': [data[x].isna().sum() for x in data.columns],\n",
    "            'zero_values': [data[x].eq(0).sum() for x in data.columns],\n",
    "            'unique_values': [data[x].nunique() for x in data.columns],\n",
    "            'top_3_freq': [data[x].value_counts().head(3).to_dict() for x in data.columns],\n",
    "            'min': [data[x].min() if data[x].dtype != object else '---' for x in data.columns],\n",
    "            'mean': [data[x].mean() if data[x].dtype != object else '---' for x in data.columns],\n",
    "            'max': [data[x].max() if data[x].dtype != object else '---' for x in data.columns],\n",
    "            'std': [data[x].std() if data[x].dtype != object else '---' for x in data.columns],\n",
    "            'lo_count': [lo_hi_count(data, x) for x in data.columns],\n",
    "            'hi_count': [lo_hi_count(data, x, low=False) for x in data.columns],\n",
    "        }, index=[x for x in data.columns]\n",
    "    )\n",
    "\n",
    "# Function to get metrics for a model\n",
    "def get_metrics(model, x_train, y_train, x_val, y_val, need_fit=True):\n",
    "    \"\"\"\n",
    "    Fit the model (if needed), make predictions, and return performance metrics.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    if isinstance(y_train, pd.core.frame.DataFrame):\n",
    "        y_train = y_train.values.ravel()\n",
    "    if need_fit:\n",
    "        model = clone(model)\n",
    "        model.fit(x_train, y_train)\n",
    "    elapsed_fit_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(x_val)\n",
    "    elapsed_predict_time = time.time() - start_time\n",
    "\n",
    "    metrics = {}\n",
    "    metrics['mae'] = mean_absolute_error(y_val, y_pred)\n",
    "    metrics['rmse'] = root_mean_squared_error(y_val, y_pred)\n",
    "    metrics['r2'] = r2_score(y_val, y_pred)\n",
    "    metrics['fit_time'] = elapsed_fit_time\n",
    "    metrics['predict_time'] = elapsed_predict_time\n",
    "    return metrics\n",
    "\n",
    "# Function to split the dataframe into training, validation, and testing sets\n",
    "def split_wrapper(df, target='price', train_size=0.7, test_size=0.5):\n",
    "    \"\"\"\n",
    "    Split the dataframe into training, validation, and test sets.\n",
    "    \"\"\"\n",
    "    X = df.drop(target, axis=1).copy()\n",
    "    y = df[target].copy()\n",
    "    X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, train_size=train_size, random_state=RANDOM_STATE)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Function to get cross-validated metrics for a model\n",
    "def get_metricsCV(model, x_train, y_train, cv=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return averaged performance metrics.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    scoring = ['neg_mean_absolute_error', 'neg_root_mean_squared_error', 'r2']\n",
    "    cv_results = cross_validate(model, x_train, y_train, cv=cv, scoring=scoring, return_train_score=False)\n",
    "    metrics['fit_time'] = np.mean(cv_results['fit_time'])\n",
    "    metrics['predict_time'] = np.mean(cv_results['score_time'])\n",
    "    metrics['mae'] = -np.mean(cv_results['test_neg_mean_absolute_error'])\n",
    "    metrics['rmse'] = -np.mean(cv_results['test_neg_root_mean_squared_error'])\n",
    "    metrics['r2'] = np.mean(cv_results['test_r2'])\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd48e1fb-ff2a-41de-aa49-c7b5df19b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дубликатов: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>count</th>\n",
       "      <th>NaNs</th>\n",
       "      <th>zero_values</th>\n",
       "      <th>unique_values</th>\n",
       "      <th>top_3_freq</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>lo_count</th>\n",
       "      <th>hi_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_apartment</th>\n",
       "      <td>int64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>129546</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 129546, 1: 1209}</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>129546</td>\n",
       "      <td>130755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_elevator</th>\n",
       "      <td>int64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>13353</td>\n",
       "      <td>2</td>\n",
       "      <td>{1: 117402, 0: 13353}</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>130755</td>\n",
       "      <td>117402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>int64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>{2: 49303, 1: 38906, 3: 34205}</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.11</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_type_int</th>\n",
       "      <td>int64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>1726</td>\n",
       "      <td>6</td>\n",
       "      <td>{4: 73635, 2: 22764, 1: 21269}</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floor</th>\n",
       "      <td>int64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>{2: 13606, 3: 12656, 5: 11812}</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.42</td>\n",
       "      <td>44.00</td>\n",
       "      <td>5.55</td>\n",
       "      <td>0</td>\n",
       "      <td>3779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floors_total</th>\n",
       "      <td>int64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>{9: 23406, 17: 21647, 12: 16086}</td>\n",
       "      <td>3.00</td>\n",
       "      <td>14.04</td>\n",
       "      <td>56.00</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0</td>\n",
       "      <td>3337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ceiling_height</th>\n",
       "      <td>float64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>{2.640000104904175: 54855, 3.0: 20987, 2.70000...</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.75</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build_year</th>\n",
       "      <td>int64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>{2017: 4071, 2018: 3973, 1968: 3272}</td>\n",
       "      <td>1,901.00</td>\n",
       "      <td>1,986.46</td>\n",
       "      <td>2,023.00</td>\n",
       "      <td>21.99</td>\n",
       "      <td>623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flats_count</th>\n",
       "      <td>int64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>705</td>\n",
       "      <td>{80: 3926, 144: 2632, 84: 2475}</td>\n",
       "      <td>1.00</td>\n",
       "      <td>252.23</td>\n",
       "      <td>1,630.00</td>\n",
       "      <td>206.71</td>\n",
       "      <td>0</td>\n",
       "      <td>6073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitchen_area</th>\n",
       "      <td>float64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2627</td>\n",
       "      <td>{6.0: 14581, 10.0: 12389, 9.0: 8907}</td>\n",
       "      <td>2.90</td>\n",
       "      <td>10.11</td>\n",
       "      <td>70.00</td>\n",
       "      <td>5.17</td>\n",
       "      <td>0</td>\n",
       "      <td>9584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_area</th>\n",
       "      <td>float64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3061</td>\n",
       "      <td>{38.0: 3337, 45.0: 2625, 39.0: 2308}</td>\n",
       "      <td>19.90</td>\n",
       "      <td>60.73</td>\n",
       "      <td>349.00</td>\n",
       "      <td>32.69</td>\n",
       "      <td>0</td>\n",
       "      <td>6907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>living_area</th>\n",
       "      <td>float64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3965</td>\n",
       "      <td>{19.0: 5639, 20.0: 4559, 30.0: 3582}</td>\n",
       "      <td>10.00</td>\n",
       "      <td>36.08</td>\n",
       "      <td>230.00</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0</td>\n",
       "      <td>5459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>int64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7744</td>\n",
       "      <td>{10500000: 2143, 9500000: 1959, 12500000: 1844}</td>\n",
       "      <td>70,000.00</td>\n",
       "      <td>17,456,666.65</td>\n",
       "      <td>336,000,000.00</td>\n",
       "      <td>22,537,206.42</td>\n",
       "      <td>0</td>\n",
       "      <td>12966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>float64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15208</td>\n",
       "      <td>{37.564212799072266: 544, 37.56404113769531: 3...</td>\n",
       "      <td>36.86</td>\n",
       "      <td>37.59</td>\n",
       "      <td>37.95</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>float64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15649</td>\n",
       "      <td>{55.77080535888672: 528, 55.7851676940918: 352...</td>\n",
       "      <td>55.21</td>\n",
       "      <td>55.73</td>\n",
       "      <td>56.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>130755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24387</td>\n",
       "      <td>{24195: 516, 24035: 212, 24057: 139}</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14,003.95</td>\n",
       "      <td>24,620.00</td>\n",
       "      <td>6,960.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      type   count  NaNs  zero_values  unique_values  \\\n",
       "is_apartment         int64  130755     0       129546              2   \n",
       "has_elevator         int64  130755     0        13353              2   \n",
       "rooms                int64  130755     0            0              5   \n",
       "building_type_int    int64  130755     0         1726              6   \n",
       "floor                int64  130755     0            0             44   \n",
       "floors_total         int64  130755     0            0             54   \n",
       "ceiling_height     float64  130755     0            0             61   \n",
       "build_year           int64  130755     0            0            118   \n",
       "flats_count          int64  130755     0            0            705   \n",
       "kitchen_area       float64  130755     0            0           2627   \n",
       "total_area         float64  130755     0            0           3061   \n",
       "living_area        float64  130755     0            0           3965   \n",
       "price                int64  130755     0            0           7744   \n",
       "longitude          float64  130755     0            0          15208   \n",
       "latitude           float64  130755     0            0          15649   \n",
       "building_id          int64  130755     0            0          24387   \n",
       "\n",
       "                                                          top_3_freq  \\\n",
       "is_apartment                                    {0: 129546, 1: 1209}   \n",
       "has_elevator                                   {1: 117402, 0: 13353}   \n",
       "rooms                                 {2: 49303, 1: 38906, 3: 34205}   \n",
       "building_type_int                     {4: 73635, 2: 22764, 1: 21269}   \n",
       "floor                                 {2: 13606, 3: 12656, 5: 11812}   \n",
       "floors_total                        {9: 23406, 17: 21647, 12: 16086}   \n",
       "ceiling_height     {2.640000104904175: 54855, 3.0: 20987, 2.70000...   \n",
       "build_year                      {2017: 4071, 2018: 3973, 1968: 3272}   \n",
       "flats_count                          {80: 3926, 144: 2632, 84: 2475}   \n",
       "kitchen_area                    {6.0: 14581, 10.0: 12389, 9.0: 8907}   \n",
       "total_area                      {38.0: 3337, 45.0: 2625, 39.0: 2308}   \n",
       "living_area                     {19.0: 5639, 20.0: 4559, 30.0: 3582}   \n",
       "price                {10500000: 2143, 9500000: 1959, 12500000: 1844}   \n",
       "longitude          {37.564212799072266: 544, 37.56404113769531: 3...   \n",
       "latitude           {55.77080535888672: 528, 55.7851676940918: 352...   \n",
       "building_id                     {24195: 516, 24035: 212, 24057: 139}   \n",
       "\n",
       "                        min          mean            max           std  \\\n",
       "is_apartment           0.00          0.01           1.00          0.10   \n",
       "has_elevator           0.00          0.90           1.00          0.30   \n",
       "rooms                  1.00          2.11           5.00          0.94   \n",
       "building_type_int      0.00          3.25           6.00          1.46   \n",
       "floor                  1.00          7.42          44.00          5.55   \n",
       "floors_total           3.00         14.04          56.00          6.68   \n",
       "ceiling_height         2.48          2.75           4.10          0.20   \n",
       "build_year         1,901.00      1,986.46       2,023.00         21.99   \n",
       "flats_count            1.00        252.23       1,630.00        206.71   \n",
       "kitchen_area           2.90         10.11          70.00          5.17   \n",
       "total_area            19.90         60.73         349.00         32.69   \n",
       "living_area           10.00         36.08         230.00         20.85   \n",
       "price             70,000.00 17,456,666.65 336,000,000.00 22,537,206.42   \n",
       "longitude             36.86         37.59          37.95          0.15   \n",
       "latitude              55.21         55.73          56.01          0.10   \n",
       "building_id            1.00     14,003.95      24,620.00      6,960.57   \n",
       "\n",
       "                   lo_count  hi_count  \n",
       "is_apartment         129546    130755  \n",
       "has_elevator         130755    117402  \n",
       "rooms                     0         0  \n",
       "building_type_int         0         0  \n",
       "floor                     0      3779  \n",
       "floors_total              0      3337  \n",
       "ceiling_height            0      8408  \n",
       "build_year              623         0  \n",
       "flats_count               0      6073  \n",
       "kitchen_area              0      9584  \n",
       "total_area                0      6907  \n",
       "living_area               0      5459  \n",
       "price                     0     12966  \n",
       "longitude              1779         0  \n",
       "latitude                103         0  \n",
       "building_id               0         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataframe from the specified table and drop the 'id' and 'flat_id' columns\n",
    "df = load_df(TABLE_NAME).drop(['id', 'flat_id'], axis=1)\n",
    "\n",
    "# Print the number of duplicate rows in the dataframe\n",
    "print(f'Дубликатов: {df.duplicated().sum()}')\n",
    "\n",
    "# Display various statistics for each column in the dataframe, sorted by the number of unique values\n",
    "display_statistics(df).sort_values(by='unique_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7c76712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target = ['price']\n",
    "\n",
    "# Identify categorical columns: columns with 6 or fewer unique values\n",
    "cat_columns = [x for x in df.columns if df[x].nunique() <= 6]\n",
    "\n",
    "# Identify numerical columns: columns that are not categorical and not the target variable\n",
    "num_columns = [x for x in df.columns if x not in cat_columns and x != target[0]]\n",
    "\n",
    "# Further categorize numerical columns based on their characteristics\n",
    "num_discrete_columns = ['floor', 'ceiling_height', 'flats_count', 'floors_total']\n",
    "num_time_columns = ['building_id', 'build_year']\n",
    "num_area_columns = ['kitchen_area', 'living_area', 'total_area']\n",
    "num_geo_columns = ['latitude', 'longitude']\n",
    "\n",
    "# Columns to be transformed using KBinsDiscretizer\n",
    "kbins_columns = num_discrete_columns + num_time_columns + num_geo_columns\n",
    "\n",
    "# Define columns for AutoFeat transformations\n",
    "autofeat_cat_columns = ['bin5__' + x for x in kbins_columns] + ['remainder__' + x for x in cat_columns]\n",
    "autofeat_feateng_columns = (\n",
    "    ['power__' + x for x in num_area_columns] \n",
    "    + ['add__scale__distance'] \n",
    "    + ['scale__' + x for x in kbins_columns]\n",
    ")\n",
    "autofeat_columns = autofeat_cat_columns + autofeat_feateng_columns\n",
    "\n",
    "# Define columns for polynomial feature transformations\n",
    "polyfeat_columns = (\n",
    "    ['power__' + x for x in num_area_columns] \n",
    "    + ['add__scale__distance'] \n",
    "    + ['scale__' + x for x in kbins_columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c0c9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into training, validation, and test sets\n",
    "# The function 'split_wrapper' splits the data and returns the features (X) and target (y) for each set\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_wrapper(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d990be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the distance from a given point to the center of Moscow\n",
    "def calculate_distance(row):\n",
    "    return geopy.distance.geodesic(MOSCOW_CENTER, (row['latitude'], row['longitude'])).km\n",
    "\n",
    "# Custom transformer to add a new feature 'scale__distance' representing the distance to Moscow center\n",
    "class FeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_new = pd.DataFrame(X).copy()\n",
    "        X_new['scale__distance'] = scale(X_new.apply(calculate_distance, axis=1))\n",
    "        return pd.DataFrame(X_new['scale__distance'])\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return ['scale__distance']\n",
    "\n",
    "# Wrapper for AutoFeatRegressor to integrate it into scikit-learn pipelines\n",
    "class AutoFeatWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.model.fit(X, y)\n",
    "        self.feature_names_out = self.model.all_columns_\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        index = X.index\n",
    "        transformed_X = self.model.transform(X)\n",
    "        transformed_df = pd.DataFrame(transformed_X, columns=self.feature_names_out)\n",
    "        transformed_df.index = index\n",
    "        return transformed_df\n",
    "\n",
    "    def get_feature_names_out(self, X=None):\n",
    "        return self.feature_names_out\n",
    "\n",
    "# Custom ColumnTransformer that returns a DataFrame instead of a numpy array\n",
    "class DataFrameColumnTransformer(ColumnTransformer):\n",
    "    def __init__(self, transformers, remainder='passthrough'):\n",
    "        super().__init__(transformers, remainder=remainder)\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = super().transform(X)\n",
    "        feature_names_out = self.get_feature_names_out()\n",
    "        return pd.DataFrame(X_transformed, columns=feature_names_out)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        X_transformed = super().fit_transform(X, y)\n",
    "        feature_names_out = self.get_feature_names_out()\n",
    "        return pd.DataFrame(X_transformed, columns=feature_names_out)\n",
    "\n",
    "# Custom transformer to remove duplicate columns\n",
    "class DuplicatesRemover(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X_df = pd.DataFrame(X).copy()\n",
    "        self.original_columns_ = X_df.columns.tolist()\n",
    "        X_df = X_df.T.drop_duplicates().T\n",
    "        self.columns_to_keep_ = X_df.columns.tolist()\n",
    "        self.dropped_columns_ = [col for col in self.original_columns_ if col not in self.columns_to_keep_]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_df = pd.DataFrame(X, columns=self.original_columns_)\n",
    "        return X_df[self.columns_to_keep_]\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return self.columns_to_keep_\n",
    "\n",
    "# Define a pipeline for power transformation and scaling\n",
    "power_scale_transformer = Pipeline([\n",
    "    ('pwr', PowerTransformer(method='box-cox')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define a preprocessor to apply transformations to specified columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('power', power_scale_transformer, num_area_columns),\n",
    "        ('bin5', KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='kmeans', subsample=None, random_state=RANDOM_STATE), kbins_columns),\n",
    "        ('add', FeatureAdder(), num_geo_columns),\n",
    "        ('scale', StandardScaler(), kbins_columns)\n",
    "    ], \n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Set the output of the preprocessor to be a DataFrame\n",
    "preprocessor.set_output(transform='pandas')\n",
    "\n",
    "# Define a feature generator to apply AutoFeat and polynomial feature transformations\n",
    "feature_generator = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('auto_feat', AutoFeatWrapper(\n",
    "            AutoFeatRegressor(\n",
    "                categorical_cols=autofeat_cat_columns, \n",
    "                feateng_cols=autofeat_feateng_columns, \n",
    "                verbose=0, \n",
    "                feateng_steps=1, \n",
    "                n_jobs=-1\n",
    "            )\n",
    "        ), autofeat_columns),\n",
    "        ('poly_features', PolynomialFeatures(\n",
    "            degree=2, interaction_only=False, \n",
    "            include_bias=False\n",
    "        ), polyfeat_columns)\n",
    "    ], \n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Set the output of the feature generator to be a DataFrame\n",
    "feature_generator.set_output(transform='pandas');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a13bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom implementation of SequentialFeatureSelector to handle batch processing and customized output\n",
    "class CustomSequentialFeatureSelector(SequentialFeatureSelector):\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            estimator, \n",
    "            k_features, \n",
    "            forward=True, \n",
    "            floating=False, \n",
    "            scoring=None, \n",
    "            cv=0,\n",
    "            n_jobs=1, \n",
    "            pre_dispatch='2*n_jobs', \n",
    "            clone_estimator=True, \n",
    "            verbose=0, \n",
    "            batch=None\n",
    "            ):\n",
    "        self.batch = batch\n",
    "        super().__init__(\n",
    "            estimator=estimator, \n",
    "            k_features=k_features, \n",
    "            forward=forward, \n",
    "            floating=floating,\n",
    "            scoring=scoring, \n",
    "            cv=cv, \n",
    "            n_jobs=n_jobs, \n",
    "            pre_dispatch=pre_dispatch, \n",
    "            clone_estimator=clone_estimator, \n",
    "            verbose=verbose\n",
    "            )\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        \"\"\"\n",
    "        Fit the model with optional batch processing and transform the data.\n",
    "        \"\"\"\n",
    "        X_full = X.copy()\n",
    "        if self.batch is not None:\n",
    "            print('Using batch: ', self.batch)\n",
    "            X = X[:self.batch]\n",
    "            y = y[:self.batch]\n",
    "        self.fit(X, y, **fit_params)\n",
    "        self.selected_features_ = list(self.k_feature_names_)\n",
    "        selected_data = self.transform(X_full)\n",
    "        return pd.DataFrame(selected_data, columns=self.get_feature_names_out(X_full.columns))\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        \"\"\"\n",
    "        Return the names of the selected features.\n",
    "        \"\"\"\n",
    "        return self.selected_features_\n",
    "\n",
    "    def set_output(self, transform=None):\n",
    "        \"\"\"\n",
    "        Placeholder method to comply with scikit-learn's API.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "# Define a custom scorer using root mean squared error\n",
    "scorer = make_scorer(root_mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Define forward and backward feature selectors using the custom sequential feature selector\n",
    "sfs_forward = CustomSequentialFeatureSelector(\n",
    "    estimator=Ridge(), \n",
    "    k_features=10, \n",
    "    forward=True, \n",
    "    scoring=scorer, \n",
    "    verbose=0, \n",
    "    cv=3, \n",
    "    n_jobs=1\n",
    ") \n",
    "\n",
    "sfs_backward = CustomSequentialFeatureSelector(\n",
    "    estimator=Ridge(), \n",
    "    k_features=10, \n",
    "    forward=False,\n",
    "    scoring=scorer, \n",
    "    verbose=0, \n",
    "    cv=0, \n",
    "    n_jobs=1, \n",
    "    batch=5000\n",
    ")\n",
    "\n",
    "# Combine the forward and backward feature selectors into a feature union\n",
    "feature_union = FeatureUnion([\n",
    "    ('sfs_forward', sfs_forward),\n",
    "    ('sfs_backward', sfs_backward)\n",
    "])\n",
    "\n",
    "# Set the output of the feature union to be a DataFrame and enable verbose feature names\n",
    "feature_union.set_output(transform='pandas')\n",
    "feature_union.set_params(verbose_feature_names_out=True)\n",
    "\n",
    "# Define the machine learning pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\n",
    "        'processor', Pipeline([\n",
    "            ('preprocessor', preprocessor),  # Apply the preprocessor transformations\n",
    "            ('feature_generator', feature_generator),  # Generate additional features\n",
    "            ('drop_duplicates_1', DuplicatesRemover()),  # Remove duplicate columns\n",
    "            ('feature_union', feature_union),  # Apply feature selection\n",
    "            ('drop_duplicates_2', DuplicatesRemover()),  # Remove duplicate columns again\n",
    "        ])\n",
    "    ), \n",
    "    (\n",
    "        'regressor', CatBoostRegressor(\n",
    "            iterations=784, \n",
    "            learning_rate=0.0933769458215897, \n",
    "            depth=9, \n",
    "            l2_leaf_reg=6.25803192908997,\n",
    "            loss_function='RMSE',\n",
    "            verbose=0,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "    )  # Train a CatBoostRegressor with the specified hyperparameters\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc45b0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using batch:  5000\n",
      "metrics['r2']=0.8839572763738286\n",
      "Тестовое предсказание: [18163527.28321603]\n",
      "Количество признаков: 15\n",
      "['sfs_forward__auto_feat__power__total_area',\n",
      " 'sfs_forward__auto_feat__add__scale__distance',\n",
      " 'sfs_forward__auto_feat__exp(power__total_area)',\n",
      " 'sfs_forward__auto_feat__Abs(power__total_area)',\n",
      " 'sfs_forward__auto_feat__Abs(add__scale__distance)',\n",
      " 'sfs_forward__poly_features__power__living_area add__scale__distance',\n",
      " 'sfs_forward__poly_features__power__total_area scale__ceiling_height',\n",
      " 'sfs_forward__poly_features__add__scale__distance scale__ceiling_height',\n",
      " 'sfs_forward__poly_features__scale__ceiling_height scale__floors_total',\n",
      " 'sfs_forward__poly_features__scale__ceiling_height scale__building_id',\n",
      " 'sfs_backward__auto_feat__power__total_area**3',\n",
      " 'sfs_backward__auto_feat__Abs(scale__longitude)',\n",
      " 'sfs_backward__poly_features__power__total_area^2',\n",
      " 'sfs_backward__poly_features__scale__ceiling_height scale__build_year',\n",
      " 'sfs_backward__poly_features__scale__latitude^2']\n",
      "CPU times: user 8min 45s, sys: 6min 57s, total: 15min 42s\n",
      "Wall time: 5min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train the pipeline with the training data, ignoring future warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', category=FutureWarning)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate performance metrics for the pipeline using the test data\n",
    "metrics = get_metrics(pipeline, X_train, y_train, X_test, y_test, need_fit=False)\n",
    "\n",
    "# Print the R^2 score of the pipeline\n",
    "print(f\"{metrics['r2']=}\")\n",
    "\n",
    "# Print a test prediction using a sample from the training data\n",
    "print(f\"Тестовое предсказание: {pipeline.predict(X_train.sample())}\")\n",
    "\n",
    "# Print the number of features used by the regressor in the pipeline\n",
    "print(f\"Количество признаков: {len(pipeline['regressor'].feature_names_)}\")\n",
    "\n",
    "# Print the names of the features used by the regressor\n",
    "pprint(pipeline['regressor'].feature_names_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c426d2ec",
   "metadata": {},
   "source": [
    "На предыдущем спринте эта модель была залогирована через MLFlow в object storage \n",
    "```\n",
    "RUN_NAME = \"6 этап: сохранение окончательной версии модели\"\n",
    "REGISTRY_MODEL_NAME = 'model_sprint_2_stage_6'\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "model = pipeline\n",
    "\n",
    "with open(\"selected_features.txt\", \"w\") as f:\n",
    "    for line in list(feature_names):\n",
    "        f.write(f\"{line}\\n\")\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    mlflow.sklearn.log_model(sk_model=model, \n",
    "        artifact_path='models', \n",
    "        registered_model_name=REGISTRY_MODEL_NAME, \n",
    "        signature=mlflow.models.infer_signature(X_test, model.predict(X_test)), \n",
    "        input_example = X_test[:10], \n",
    "        await_registration_for=60, \n",
    "        pip_requirements='../requirements.txt')\n",
    "    mlflow.log_params(model.get_params())\n",
    "    mlflow.log_artifact('selected_features.txt', \"artifacts\") \n",
    "    mlflow.log_metrics(metrics)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2cd5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель sklearn.pipeline.Pipeline.<catboost.core.CatBoostRegressor object at 0x7f5e7c4ff8b0> успешно загружена в файл: loaded_model.pkl\n",
      "Тестовое предсказание: pipeline.predict(X_test.sample())=array([8299759.40921049])\n"
     ]
    }
   ],
   "source": [
    "# Define the local path to save the downloaded model\n",
    "local_model_path = 'loaded_model.pkl'\n",
    "\n",
    "# Create an S3 client using the AWS credentials and S3 endpoint from environment variables\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "    endpoint_url=os.environ['MLFLOW_S3_ENDPOINT_URL']\n",
    ")\n",
    "\n",
    "# Download the model file from the S3 bucket to the local path\n",
    "s3_client.download_file(os.getenv('S3_BUCKET_NAME'), os.getenv('MODEL_FILE_KEY'), local_model_path)\n",
    "\n",
    "# Load the model from the local file\n",
    "model = joblib.load(local_model_path)\n",
    "\n",
    "# Print a message indicating successful model loading with details about the model\n",
    "print(f\"Модель {model.__class__.__module__}.{model.__class__.__name__}.\"\n",
    "      f\"{model._final_estimator} успешно загружена в файл: {local_model_path}\")\n",
    "\n",
    "# Print a test prediction using a sample from the test data\n",
    "print(f\"Тестовое предсказание: {pipeline.predict(X_test.sample())=}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_sprint_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
