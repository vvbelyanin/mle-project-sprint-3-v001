# Общее описание проекта

### Решаем такую-то задачу
...


### Сделано
1. ...
2. ...



# установка расширения для виртуального пространства
sudo apt-get install python3.10-venv
# создание виртуального пространства
python3.10 -m venv .mle-sprint3-venv
source .mle-sprint3-venv/bin/activate
pip install fastapi
pip install "uvicorn[standard]" 
pip install catboost 






Этап 1. Написание FastAPI-микросервиса
На этом этапе проекта вы напишете FastAPI-микросервис для обработки запросов к модели. Для этого:

    Напишите код микросервиса, который принимает запросы и выдаёт предсказания модели в формате JSON ({"score":y_pred}), используя FastAPI и uvicorn. Микросервис должен использовать класс-обработчик, который валидирует входные данные и возвращает предсказания.
    Заполните файл requirements.txt.
    Опишите в Instructions.md, как следует устанавливать и запускать микросервис с использованием виртуального окружения (venv или conda): последовательность команд и как следует к нему обращаться. Добавьте пример curl-запроса.

Результаты этапа:

    Код микросервиса в директории app, модель в директории models и заполненный файл requirements.txt.
    Инструкция в файле Instructions.md по запуску FastAPI-микросервиса:  последовательность команд или команда по запуску Shell-скрипта. Пример запроса, который мироксервис обработает корректно.
    При запуске микросервиса в Swagger на странице /docs должен быть пример запроса к микросервису. При обращении через запрос неправильного формата микросервис должен выдавать осмысленные сообщения об ошибках.

Независимо от следующих этапов микросервис должен запускаться и корректно работать по инструкции в Instructions.md.
Этап 2. Контейнеризация микросервиса
На этом этапе проекта вы напишете Docker Compose для контейнеризации вашего FastAPI-микросервиса. Для этого:

    Напишите Dockerfile для сборки образа сервиса.
    Напишите файл docker-compose.yaml для запуска сервиса в режиме Docker Compose.
    Напишите инструкцию по запуску FastAPI-микросервиса без Docker Compose с помощью команд docker image и docker container.
    Напишите инструкцию по запуску FastAPI-микросервиса в режиме Docker Compose. Это должна быть одна команда и её описание.
    Приведите пример запроса, который микросервис обработает корректно.

Результаты этапа:

    Dockerfile, в котором указаны инструкции для сборки образа FastAPI-микросервиса с ML-моделью.
    Файл docker-compose.yaml, в котором описан сервис с ML-моделью.
    Инструкция по запуску FastAPI-микросервиса: последовательность команд или Shell-скрипт без использования Docker Compose и c ним. А также пример запроса, который микросервис обработает корректно.

Этап 3. Запуск сервисов для системы мониторинга
На этом этапе проекта вы добавите к сервису с моделью систему мониторинга: Prometheus и Grafana. Для этого:

    Добавьте в Docker Compose описание сервиса Prometheus.
    Добавьте для Prometheus собственный конфиг prometheus.yml, который  подключается в качестве тома в Docker, как это было сделано в уроках.
    Добавьте в Docker Compose описание сервиса Grafana.
    Добавьте в микросервис экспортёр с помощью prometheus_fastapi_instrumentator. На этом этапе необязательно писать свои собственные метрики.
    Напишите инструкцию по запуску микросервиса и системы мониторинга: FastAPI-микросервиса, Prometheus и Grafana в режиме Docker Сompose. Это должна быть одна команда и её описание.

Помните, что параметры подключения — в нашем случае логин и пароль для пользователя Grafana — не должны храниться в Git. Укажите, где необходимо заполнять эти поля в инструкции, однако не добавляйте в Git файл .env со значениями переменных. 
Результаты этапа:

    Обновлённый относительно второго этапа docker-compose.yaml, в котором теперь присутствует описание сервисов Prometheus и Grafana.
    Заполненный prometheus.yml.
    Обновлённый относительно первых двух этапов файл с микросервисом, в котором теперь присутствует запуск экспортёра с помощью prometheus_fastapi_instrumentator.
    Инструкция по запуску системы мониторинга в файле Instructions.md, а также указание, по какому адресу находятся:
     
     a. микросервис,
     b. Prometheus,
     c. Grafana.

На этом этапе у вас изменятся код микросервиса, requirements.txt и, возможно, Dockerfile_ml_service. Убедитесь, что инструкции для первого и второго этапов работают верно с учётом изменения в этих файлах.
Этап 4. Построение дашборда для мониторинга
На этом этапе: 

    Опишите в файле Monitoring.md, какие ML-метрики реального времени, а также инфраструктурного и прикладного уровней вы хотите использовать для мониторинга приложения.
    Добавьте подсчёт и экспорт как минимум двух метрик разного типа с помощью prometheus_client в FastAPI-приложение.
    Напишите скрипт .py или Shell, который будет симулировать нагрузку на сервис, и добавьте инструкцию по его запуску. Этот скрипт может содержать последовательность curl-команд к сервису, и тогда это будет Shell-скрипт. Или же обращения к сервису с помощью библиотеки requests — тогда это .py-скрипт.
    Постройте дашборд в Grafana. В нём должны использоваться как минимум 4 аналитические панели и 3 вида графиков.
    Сохраните дашборд в JSON-файл с названием dashboard.json и загрузите его в Git.
    Добавьте скриншот вашего дашборда и его описание: объясните, почему панели выглядят именно так, почему используются конкретные виды графиков, на какие вопросы отвечает дашборд и т. д. — в Monitoring.md.

Результаты этапа:

    В файле Monitoring.md есть описание выбранных метрик и обоснование их выбора.
    В файле Instructions.md есть инструкция по запуску скрипта, симулирующего нагрузку на сервис.
    В файле Monitoring.md есть описание дашборда.
    Файл с дашбордом dashboard.json.